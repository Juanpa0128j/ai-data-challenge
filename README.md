# Medical AI Dashboard - XGBoost Literature Classification

![Dashboard Preview](https://img.shields.io/badge/Status-Ready_for_V0-success)
![Model](https://img.shields.io/badge/Model-XGBoost-orange)
![API](https://img.shields.io/badge/API-Flask%2FNext.js-blue)
![Last Update](https://img.shields.io/badge/Last_Update-August_2025-green)

## Res√∫men

Dashboard profesional para clasificaci√≥n autom√°tica de literatura m√©dica usando XGBoost. Sistema completo con API en tiempo real, visualizaciones interactivas y datos reales del modelo entrenado.

### Caracter√≠sticas 
- **4 Categor√≠as M√©dicas:** Cardiovascular, Neurol√≥gico, Hepatorenal, Oncol√≥gico
- **Predicciones en Tiempo Real** con API Flask/Next.js
- **Visualizaciones Interactivas** con m√©tricas de rendimiento
- **Datos Reales** del modelo entrenado (3,565 muestras)
- **Deployment Ready** para Vercel/GitHub Pages

## ¬øC√≥mo ejecutar?

```bash
# 1. Clonar el repositorio
git clone https://github.com/Juanpa0128j/ai-data-challenge.git
cd ai-data-challenge

# 2. Iniciar la aplicaci√≥n (todo en uno)
bash start.sh
```

El script `start.sh` realiza autom√°ticamente:
- Creaci√≥n de un entorno virtual de Python
- Instalaci√≥n de todas las dependencias (Python y Node.js)
- Verificaci√≥n de la instalaci√≥n de XGBoost
- Inicio del servidor API Flask y el frontend Next.js

Una vez iniciado, accede a:
- **Frontend**: http://localhost:3000
- **API**: http://localhost:5000/api/health

## Mejor rendimiento alcanzado

| M√©trica | Valor |
|---------|-------|
| **Accuracy** | 80.79% |
| **Precision (Macro)** | 97.02% |
| **Recall (Macro)** | 85.62% |
| **F1-Score (Macro)** | 90.78% |
| **ROC-AUC (Macro)** | 97.40% |
| **Muestras** | 3,565 |

### Rendimiento por Categor√≠a

| Categor√≠a | Precisi√≥n | Recall | F1-Score |
|-----------|-----------|--------|----------|
| **Cardiovascular** | 97.42% | 89.37% | 93.22% |
| **Neurol√≥gico** | 93.82% | 93.30% | 93.56% |
| **Hepatorenal** | 98.81% | 76.50% | 86.23% |
| **Oncol√≥gico** | 98.04% | 83.33% | 90.09% |

### Resultados de Cross-Validation

| M√©trica | Valor Medio | Desviaci√≥n Std |
|---------|------------|----------------|
| **Accuracy** | 74.86% | ¬±1.73% |
| **F1-Score (Macro)** | 87.67% | ¬±0.99% |
| **F1-Score (Micro)** | 88.43% | ¬±0.92% |

**Tiempo de entrenamiento:** 17 minutos, 15 segundos

## API Endpoints

La API Flask proporciona los siguientes endpoints para interactuar con el modelo:

### Health Check

```http
GET /api/health
```

Verifica el estado de la API y si el modelo est√° cargado correctamente.

**Respuesta:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "vectorizer_loaded": true,
  "timestamp": "2025-08-25T15:30:45.279319"
}
```

### Predicci√≥n

```http
POST /api/predict
```

Realiza una predicci√≥n de categor√≠as m√©dicas para un texto.

**Body:**
```json
{
  "text": "Adrenoleukodystrophy: survey of 303 cases: biochemistry, diagnosis, and therapy."
}
```

**Respuesta:**
```json
{
  "text": "Adrenoleukodystrophy: survey of 303 cases: biochemistry, diagnosis, and therapy.",
  "predictions": [
    {
      "category": "neurological",
      "probability": 0.92,
      "predicted": true,
      "confidence": "Alta"
    },
    {
      "category": "cardiovascular",
      "probability": 0.12,
      "predicted": false,
      "confidence": "Baja"
    },
    {
      "category": "hepatorenal",
      "probability": 0.08,
      "predicted": false,
      "confidence": "Baja"
    },
    {
      "category": "oncological",
      "probability": 0.03,
      "predicted": false,
      "confidence": "Baja"
    }
  ],
  "feature_importance": [
    {
      "feature": "adrenoleukodystrophy",
      "value": 1.0,
      "importance": 0.034
    }
  ],
  "prediction_summary": {
    "total_categories": 1,
    "max_probability": 0.92,
    "primary_category": "neurological"
  },
  "timestamp": "2025-08-25T15:31:12.456789"
}
```

### Informaci√≥n del Modelo

```http
GET /api/model-info
```

Obtiene informaci√≥n detallada sobre el modelo cargado.

**Respuesta:**
```json
{
  "model_type": "OneVsRestClassifier",
  "categories": ["cardiovascular", "neurological", "hepatorenal", "oncological"],
  "n_features": 5000,
  "model_params": {
    "n_estimators": 200,
    "max_depth": 8,
    "learning_rate": 0.05
  },
  "training_info": {
    "algorithm": "XGBoost",
    "task_type": "Multi-label Classification",
    "text_processing": "TF-IDF Vectorization"
  }
}
```

### Ejemplos de Demostraci√≥n

```http
GET /api/demo-examples
```

Proporciona ejemplos predefinidos para probar el modelo.

### Estad√≠sticas

```http
GET /api/statistics
```

Obtiene estad√≠sticas detalladas del modelo y dataset, incluyendo m√©tricas de rendimiento.

## Uso del Dashboard

El dashboard Next.js proporciona una interfaz intuitiva para:

1. **Predicciones en tiempo real**: Ingresar texto m√©dico y ver resultados de clasificaci√≥n
2. **Visualizaci√≥n de m√©tricas**: Gr√°ficos de rendimiento del modelo
3. **Ejemplos predefinidos**: Casos de prueba para demostraci√≥n
4. **Explicabilidad**: Visualizaci√≥n de caracter√≠sticas importantes

## Estructura del proyecto

```
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ challenge_data-18-ago.csv  # Dataset para entrenamiento
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ xgboost_model.pkl          # Modelo entrenado serializado
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îî‚îÄ‚îÄ xgboost_results.json       # Resultados y m√©tricas del modelo
‚îú‚îÄ‚îÄ logs/                          # Logs de entrenamiento y ejecuci√≥n
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.py                 # API Flask para predicciones
‚îÇ   ‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ xgboost_config.py  # Configuraciones del modelo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ xgboost_trainer.py # Pipeline de entrenamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ enhanced_xgboost.py # Modelo XGBoost mejorado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ xgboost_evaluator.py # Evaluaci√≥n y m√©tricas
‚îÇ   ‚îî‚îÄ‚îÄ frontend/                  # Aplicaci√≥n Next.js
‚îÇ       ‚îú‚îÄ‚îÄ app/                   # Estructura App Router de Next.js
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ api/               # API Routes de Next.js
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ demo-examples/ # Ejemplos de demostraci√≥n
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health/        # Endpoint de estado
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict/       # Endpoint de predicci√≥n
‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ statistics/    # Endpoint de estad√≠sticas
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx           # P√°gina principal del dashboard
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ layout.tsx         # Layout principal
‚îÇ       ‚îú‚îÄ‚îÄ components/            # Componentes React reutilizables
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ui/                # Componentes de interfaz 
‚îÇ       ‚îú‚îÄ‚îÄ lib/                   # Utilidades y funciones auxiliares
‚îÇ       ‚îî‚îÄ‚îÄ public/                # Archivos est√°ticos
‚îú‚îÄ‚îÄ run_xgboost_pipeline.py        # Script principal para entrenamiento y evaluaci√≥n
‚îú‚îÄ‚îÄ start.sh                       # Script para iniciar API y frontend
‚îî‚îÄ‚îÄ requirements.txt               # Dependencias del proyecto
```

## Instalaci√≥n

### Requisitos del sistema

- Python 3.9+
- Node.js 18+ (para el frontend)
- pip (gestor de paquetes de Python)
- npm (gestor de paquetes de Node.js)

### M√©todos de instalaci√≥n

#### M√©todo 1: Script automatizado (recomendado)

El script `start.sh` automatiza todo el proceso de instalaci√≥n e inicio:

```bash
# Ejecutar el script automatizado
bash start.sh
```

Este script realiza las siguientes tareas:
1. Crea un entorno virtual de Python
2. Instala todas las dependencias de Python
3. Verifica la instalaci√≥n de XGBoost
4. Instala las dependencias de Next.js
5. Inicia tanto el API Flask como el frontend Next.js

#### M√©todo 2: Instalaci√≥n manual

Si prefieres instalar manualmente:

1. Crear y activar un entorno virtual:

```bash
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

2. Instalar dependencias de Python:

```bash
pip install -r requirements.txt
```

3. Verificar instalaci√≥n de XGBoost:

```bash
python -c "import xgboost; print(f'XGBoost version: {xgboost.__version__}')"
```

4. Instalar dependencias del frontend:

```bash
cd src/frontend
npm install
```

5. Iniciar servicios por separado:

```bash
# Terminal 1: API
cd src/api
python api.py

# Terminal 2: Frontend
cd src/frontend
npm run dev
```

# Uso del backend para manipular el modelo

### 1. Entrenar el Modelo

#### Entrenamiento b√°sico:
```bash
python run_xgboost_pipeline.py train
```

#### Con configuraci√≥n espec√≠fica:
```bash
python run_xgboost_pipeline.py train --config high_performance
```

#### Con datos personalizados:
```bash
python run_xgboost_pipeline.py train --data-path data/mi_dataset.csv
```

#### B√∫squeda de hiperpar√°metros:
```bash
python run_xgboost_pipeline.py train --hyperparameter-search
```

### 2. Evaluar el Modelo

```bash
python run_xgboost_pipeline.py evaluate --model-path models/xgboost_model.pkl
```

Con comparaci√≥n baseline:
```bash
python run_xgboost_pipeline.py evaluate --model-path models/xgboost_model.pkl --baseline-results results/baseline_results.json
```

### 3. Analizar el Modelo

#### An√°lisis de importancia de caracter√≠sticas:
```bash
python run_xgboost_pipeline.py analyze --model-path models/xgboost_model.pkl
```

#### Explicar predicci√≥n espec√≠fica:
```bash
python run_xgboost_pipeline.py analyze --model-path models/xgboost_model.pkl --text "Patient presents with cardiovascular symptoms..."
```

#### Modo interactivo:
```bash
python run_xgboost_pipeline.py analyze --model-path models/xgboost_model.pkl --interactive
```

### 4. Comparar Configuraciones

```bash
python run_xgboost_pipeline.py compare-configs
```

## Configuraciones Disponibles

### `default`
- **Prop√≥sito**: Configuraci√≥n balanceada para uso general
- **Estimadores**: 100
- **Profundidad**: 6
- **Learning Rate**: 0.1

### `fast_training`
- **Prop√≥sito**: Entrenamiento r√°pido para prototipado
- **Estimadores**: 50
- **Profundidad**: 4
- **Learning Rate**: 0.2

### `high_performance`
- **Prop√≥sito**: M√°ximo rendimiento (m√°s lento)
- **Estimadores**: 200
- **Profundidad**: 8
- **Learning Rate**: 0.05
- **Subsample**: 0.8
- **Colsample Bytree**: 0.8
- **Reg Alpha**: 0.1
- **Early Stopping**: 15 rondas

### `regularized`
- **Prop√≥sito**: Control de overfitting
- **Regularizaci√≥n L1**: 0.5
- **Regularizaci√≥n L2**: 2.0
- **Gamma**: 0.1

## Caracter√≠sticas del Modelo XGBoost

```python
if XGBOOST_AVAILABLE:
    self.models['XGBoost'] = OneVsRestClassifier(
        XGBClassifier(
            random_state=42,
            n_estimators=200,
            max_depth=8,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            min_child_weight=1,
            gamma=0.0,
            reg_alpha=0.1,
            reg_lambda=1.0,
            eval_metric='logloss',
            early_stopping_rounds=15
        )
    )
```

### Ventajas de XGBoost:
- **Alto rendimiento**: Optimizado para velocidad y precisi√≥n
- **Regularizaci√≥n**: Control autom√°tico de overfitting
- **Manejo de missing values**: Autom√°tico
- **Feature importance**: An√°lisis detallado de caracter√≠sticas
- **Early stopping**: Previene sobreentrenamiento

## Salidas y Resultados

### Archivos generados durante entrenamiento:
- `models/xgboost_model.pkl`: Modelo entrenado completo
- `results/xgboost_results.json`: M√©tricas detalladas
- `results/xgboost_training_YYYYMMDD_HHMMSS.log`: Log de entrenamiento

### Archivos generados durante evaluaci√≥n:
- `results/xgboost_comprehensive_evaluation.png`: Visualizaciones
- `results/xgboost_detailed_evaluation.json`: M√©tricas detalladas
- `results/xgboost_evaluation_summary.txt`: Resumen legible
- `results/xgboost_feature_importance.png`: Importancia de caracter√≠sticas

### Archivos generados durante an√°lisis:
- `results/shap_explanation_[class].png`: Explicaciones SHAP
- `results/xgboost_confusion_matrices.png`: Matrices de confusi√≥n

## M√©tricas Evaluadas

### M√©tricas b√°sicas:
- **Accuracy**: Precisi√≥n general
- **F1-Score**: Macro, Micro, Weighted
- **Precision/Recall**: Macro, Micro
- **Hamming Loss**: Error en multi-label
- **Jaccard Score**: Similitud de conjuntos

### M√©tricas por clase:
- **AUC-ROC**: √Årea bajo curva ROC
- **Average Precision**: √Årea bajo curva PR
- **Support**: N√∫mero de muestras por clase

### An√°lisis multi-label:
- **Exact Match Ratio**: Predicciones perfectas
- **Label Ranking Loss**: Error de ranking
- **Frecuencia de etiquetas**: Distribuci√≥n real vs predicha

## üß™ Uso Avanzado del Pipeline

La herramienta de l√≠nea de comandos `run_xgboost_pipeline.py` permite realizar diversas operaciones:

```bash
# Ver opciones disponibles
python run_xgboost_pipeline.py --help
```

### Entrenar con distintas configuraciones

```bash
# Configuraci√≥n por defecto
python run_xgboost_pipeline.py train

# Configuraci√≥n de alto rendimiento
python run_xgboost_pipeline.py train --config high_performance

# B√∫squeda de hiperpar√°metros
python run_xgboost_pipeline.py train --hyperparameter-search
```

### Evaluaci√≥n detallada

```bash
# Evaluaci√≥n completa del modelo
python run_xgboost_pipeline.py evaluate --model-path models/xgboost_model.pkl

# Evaluaci√≥n con datos espec√≠ficos
python run_xgboost_pipeline.py evaluate --model-path models/xgboost_model.pkl --data-path data/custom_test_data.csv
```

### Explicabilidad

```bash
# An√°lisis SHAP para explicaciones
python run_xgboost_pipeline.py analyze --model-path models/xgboost_model.pkl --interactive
```

#  Contribuciones

¬°Las contribuciones son bienvenidas! Sigue estos pasos:

1. Fork el repositorio
2. Crea una rama (`git checkout -b feature/nueva-funcionalidad`)
3. Haz commit de tus cambios (`git commit -m 'A√±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## Gu√≠as para contribuir

- Mant√©n el estilo de c√≥digo consistente
- A√±ade tests para nuevas funcionalidades
- Actualiza la documentaci√≥n seg√∫n sea necesario
- Sigue las convenciones de commits sem√°nticos

## Licencia

Este proyecto est√° bajo la licencia MIT. Ver archivo LICENSE para detalles.

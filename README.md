# XGBoost Training Pipeline

Una pipeline completa para entrenar y evaluar modelos XGBoost en la clasificaci√≥n de literatura m√©dica.

## Estructura del Proyecto

```
# Medical AI Dashboard - XGBoost Literature Classification

![Dashboard Preview](https://img.shields.io/badge/Status-Ready_for_V0-success)
![Model](https://img.shields.io/badge/Model-XGBoost-orange)
![API](https://img.shields.io/badge/API-Flask%2FNext.js-blue)

## üéØ Resumen Ejecutivo

Dashboard profesional para clasificaci√≥n autom√°tica de literatura m√©dica usando XGBoost. Sistema completo con API en tiempo real, visualizaciones interactivas y datos reales del modelo entrenado.

### ‚ú® Caracter√≠sticas Principales
- **4 Categor√≠as M√©dicas:** Cardiovascular, Neurol√≥gico, Hepatorenal, Oncol√≥gico
- **Predicciones en Tiempo Real** con API Flask/Next.js
- **Visualizaciones Interactivas** con m√©tricas de rendimiento
- **Datos Reales** del modelo entrenado (3,565 muestras)
- **Deployment Ready** para Vercel/GitHub Pages

## üìä Rendimiento del Modelo

| M√©trica | Valor |
|---------|-------|
| **Accuracy** | 85.47% |
| **Precision** | 82.34% |
| **Recall** | 78.91% |
| **F1-Score** | 80.58% |
| **Muestras** | 3,565 |

## üöÄ Quick Start para V0 + Vercel

### 1. V0 Dashboard (5 minutos)
Ve a **https://v0.dev** y usa este prompt:
```
Crea un dashboard m√©dico profesional para XGBoost de clasificaci√≥n de literatura m√©dica.

COMPONENTES PRINCIPALES:
1. Header con "Medical AI Dashboard" y m√©tricas en cards (Accuracy 85%, Precision 82%, etc.)
2. Predictor en tiempo real: textarea + bot√≥n "Predecir" + resultados con probabilidades
3. Matriz de confusi√≥n como heatmap interactivo 4x4
4. Gr√°fico de barras horizontales con importancia de caracter√≠sticas
5. Line charts con curvas de entrenamiento (loss/accuracy vs iteraciones)
6. Galer√≠a de ejemplos m√©dicos con casos reales

CONEXI√ìN API: 
- POST /api/predict para predicciones {"text": "texto m√©dico"}
- GET /api/statistics para m√©tricas del modelo
- GET /api/demo-examples para ejemplos m√©dicos

ESTILO: Tema m√©dico profesional (azul #2563eb, blanco), responsive, animaciones suaves
```

### 2. Conectar con Vercel (10 minutos)
```bash
# Despu√©s de generar en V0, copiar nuestras API routes
cp -r vercel/api/* [proyecto-v0]/pages/api/
# o para App Router: cp -r vercel/api/* [proyecto-v0]/app/api/

# Deploy a Vercel
cd [proyecto-v0]
vercel --prod
```

### 3. URLs Finales
- **Dashboard:** https://tu-proyecto.vercel.app
- **API:** https://tu-proyecto.vercel.app/api/predict
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ xgboost_config.py          # Configuraciones del modelo
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ xgboost_trainer.py     # Pipeline de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ enhanced_xgboost.py    # Modelo XGBoost mejorado
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/
‚îÇ       ‚îî‚îÄ‚îÄ xgboost_evaluator.py   # Evaluaci√≥n y m√©tricas
‚îú‚îÄ‚îÄ models/                        # Modelos entrenados
‚îú‚îÄ‚îÄ results/                       # Resultados y visualizaciones
‚îú‚îÄ‚îÄ run_xgboost_pipeline.py        # Script principal
‚îî‚îÄ‚îÄ requirements_xgboost.txt       # Dependencias
```

## Instalaci√≥n

1. Instalar dependencias:
```bash
pip install -r requirements_xgboost.txt
```

2. Verificar instalaci√≥n de XGBoost:
```bash
python -c "import xgboost; print(f'XGBoost version: {xgboost.__version__}')"
```

## Uso

### 1. Entrenar el Modelo

#### Entrenamiento b√°sico:
```bash
python run_xgboost_pipeline.py train
```

#### Con configuraci√≥n espec√≠fica:
```bash
python run_xgboost_pipeline.py train --config high_performance
```

#### Con datos personalizados:
```bash
python run_xgboost_pipeline.py train --data-path data/mi_dataset.csv
```

#### B√∫squeda de hiperpar√°metros:
```bash
python run_xgboost_pipeline.py train --hyperparameter-search
```

### 2. Evaluar el Modelo

```bash
python run_xgboost_pipeline.py evaluate --model-path models/xgboost_model.pkl
```

Con comparaci√≥n baseline:
```bash
python run_xgboost_pipeline.py evaluate --model-path models/xgboost_model.pkl --baseline-results results/baseline_results.json
```

### 3. Analizar el Modelo

#### An√°lisis de importancia de caracter√≠sticas:
```bash
python run_xgboost_pipeline.py analyze --model-path models/xgboost_model.pkl
```

#### Explicar predicci√≥n espec√≠fica:
```bash
python run_xgboost_pipeline.py analyze --model-path models/xgboost_model.pkl --text "Patient presents with cardiovascular symptoms..."
```

#### Modo interactivo:
```bash
python run_xgboost_pipeline.py analyze --model-path models/xgboost_model.pkl --interactive
```

### 4. Comparar Configuraciones

```bash
python run_xgboost_pipeline.py compare-configs
```

## Configuraciones Disponibles

### `default`
- **Prop√≥sito**: Configuraci√≥n balanceada para uso general
- **Estimadores**: 100
- **Profundidad**: 6
- **Learning Rate**: 0.1

### `fast_training`
- **Prop√≥sito**: Entrenamiento r√°pido para prototipado
- **Estimadores**: 50
- **Profundidad**: 4
- **Learning Rate**: 0.2

### `high_performance`
- **Prop√≥sito**: M√°ximo rendimiento (m√°s lento)
- **Estimadores**: 200
- **Profundidad**: 8
- **Learning Rate**: 0.05
- **Early Stopping**: 15 rondas

### `regularized`
- **Prop√≥sito**: Control de overfitting
- **Regularizaci√≥n L1**: 0.5
- **Regularizaci√≥n L2**: 2.0
- **Gamma**: 0.1

## Caracter√≠sticas del Modelo XGBoost

```python
if XGBOOST_AVAILABLE:
    self.models['XGBoost'] = OneVsRestClassifier(
        XGBClassifier(
            random_state=42,
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            eval_metric='logloss'
        )
    )
```

### Ventajas de XGBoost:
- **Alto rendimiento**: Optimizado para velocidad y precisi√≥n
- **Regularizaci√≥n**: Control autom√°tico de overfitting
- **Manejo de missing values**: Autom√°tico
- **Feature importance**: An√°lisis detallado de caracter√≠sticas
- **Early stopping**: Previene sobreentrenamiento

## API Program√°tica

### Entrenamiento b√°sico:
```python
from src.training.xgboost_trainer import XGBoostTrainer
from config.xgboost_config import get_config

# Cargar configuraci√≥n
config = get_config('high_performance')

# Entrenar modelo
trainer = XGBoostTrainer(config)
results = trainer.run_full_pipeline(
    data_path='data/mi_dataset.csv',
    perform_cv=True
)

print(f"F1-Score: {results['test_metrics']['f1_macro']:.4f}")
```

### An√°lisis del modelo:
```python
from src.models.enhanced_xgboost import EnhancedXGBoostModel

# Cargar modelo entrenado
model = EnhancedXGBoostModel('models/xgboost_model.pkl')

# Hacer predicci√≥n
result = model.predict_single("Patient shows cardiovascular symptoms")
print(f"Predicted labels: {result['predicted_labels']}")

# Analizar importancia de caracter√≠sticas
importance = model.analyze_feature_importance(top_n=20)
```

### Evaluaci√≥n comprensiva:
```python
from src.evaluation.xgboost_evaluator import XGBoostEvaluator

# Evaluar modelo
evaluator = XGBoostEvaluator('models/xgboost_model.pkl')
results = evaluator.comprehensive_evaluation(X_test, y_test)

# Generar reporte
report = evaluator.generate_model_report()
print(report)
```

## Salidas y Resultados

### Archivos generados durante entrenamiento:
- `models/xgboost_model.pkl`: Modelo entrenado completo
- `results/xgboost_results.json`: M√©tricas detalladas
- `results/xgboost_training_YYYYMMDD_HHMMSS.log`: Log de entrenamiento

### Archivos generados durante evaluaci√≥n:
- `results/xgboost_comprehensive_evaluation.png`: Visualizaciones
- `results/xgboost_detailed_evaluation.json`: M√©tricas detalladas
- `results/xgboost_evaluation_summary.txt`: Resumen legible
- `results/xgboost_feature_importance.png`: Importancia de caracter√≠sticas

### Archivos generados durante an√°lisis:
- `results/shap_explanation_[class].png`: Explicaciones SHAP
- `results/xgboost_confusion_matrices.png`: Matrices de confusi√≥n

## M√©tricas Evaluadas

### M√©tricas b√°sicas:
- **Accuracy**: Precisi√≥n general
- **F1-Score**: Macro, Micro, Weighted
- **Precision/Recall**: Macro, Micro
- **Hamming Loss**: Error en multi-label
- **Jaccard Score**: Similitud de conjuntos

### M√©tricas por clase:
- **AUC-ROC**: √Årea bajo curva ROC
- **Average Precision**: √Årea bajo curva PR
- **Support**: N√∫mero de muestras por clase

### An√°lisis multi-label:
- **Exact Match Ratio**: Predicciones perfectas
- **Label Ranking Loss**: Error de ranking
- **Frecuencia de etiquetas**: Distribuci√≥n real vs predicha

## Configuraci√≥n Avanzada

### Personalizar hiperpar√°metros:
```python
from config.xgboost_config import XGBoostConfig

custom_config = XGBoostConfig(
    n_estimators=300,
    max_depth=10,
    learning_rate=0.03,
    reg_alpha=0.1,
    reg_lambda=1.5,
    subsample=0.8,
    colsample_bytree=0.8
)

trainer = XGBoostTrainer(custom_config)
```

### B√∫squeda de hiperpar√°metros personalizada:
```python
param_grid = {
    'estimator__n_estimators': [100, 200, 300],
    'estimator__max_depth': [6, 8, 10],
    'estimator__learning_rate': [0.03, 0.1, 0.2],
    'estimator__reg_alpha': [0, 0.1, 0.5],
    'estimator__reg_lambda': [1, 1.5, 2]
}

search_results = trainer.hyperparameter_search(X_train, y_train, param_grid)
```

## Interpretabilidad del Modelo

### An√°lisis SHAP (requiere `pip install shap`):
```python
# Explicar predicci√≥n espec√≠fica
explanation = model.explain_prediction_shap(
    text="Patient presents with neurological symptoms",
    plot=True
)

# Ver caracter√≠sticas m√°s importantes
print("Top contributing features:")
for class_name, data in explanation.items():
    print(f"{class_name}: {data['top_features'][:5]}")
```

### Importancia de caracter√≠sticas:
```python
# Analizar importancia global
importance_results = model.analyze_feature_importance(top_n=30)

# Ver caracter√≠sticas m√°s importantes por clase
for class_name, data in importance_results.items():
    print(f"\nTop features for {class_name}:")
    for feature, importance in zip(data['features'][:10], data['importances'][:10]):
        print(f"  {feature}: {importance:.4f}")
```

## Monitoreo y Logs

Los logs se generan autom√°ticamente durante el entrenamiento y incluyen:
- Progreso del entrenamiento
- M√©tricas de validaci√≥n
- Tiempo de ejecuci√≥n
- Errores y advertencias

Ubicaci√≥n: `results/xgboost_training_YYYYMMDD_HHMMSS.log`

## Extensiones Posibles

### 1. Validaci√≥n cruzada estratificada:
```python
from sklearn.model_selection import StratifiedKFold

# Implementar en trainer personalizado
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_results = trainer.cross_validate(X, y, cv=skf)
```

### 2. Optimizaci√≥n bayesiana:
```python
# Requiere: pip install optuna
import optuna

def objective(trial):
    config = XGBoostConfig(
        n_estimators=trial.suggest_int('n_estimators', 50, 300),
        max_depth=trial.suggest_int('max_depth', 3, 10),
        learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),
    )
    # ... entrenamiento y evaluaci√≥n
    return f1_score

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)
```

### 3. Ensemble con otros modelos:
```python
from sklearn.ensemble import VotingClassifier

# Combinar XGBoost con otros modelos
ensemble = VotingClassifier([
    ('xgb', xgboost_model),
    ('rf', random_forest_model),
    ('lr', logistic_regression_model)
], voting='soft')
```

## Troubleshooting

### Problemas comunes:

1. **XGBoost no se instala**:
```bash
# En Windows
conda install -c conda-forge xgboost

# En Linux/Mac
pip install --upgrade pip
pip install xgboost
```

2. **Error de memoria**:
```python
# Reducir max_features en configuraci√≥n
config.max_features = 2000

# O usar procesamiento por lotes
# Implementar en trainer personalizado
```

3. **SHAP muy lento**:
```python
# Usar muestras m√°s peque√±as
explainer = shap.TreeExplainer(estimator)
shap_values = explainer.shap_values(X_sample[:100])
```

4. **Convergencia lenta**:
```python
# Aumentar learning_rate
config.learning_rate = 0.2
# O reducir regularizaci√≥n
config.reg_alpha = 0.0
config.reg_lambda = 1.0
```

## Licencia

Este proyecto est√° bajo la licencia MIT. Ver archivo LICENSE para detalles.
